# listmonk_clone/campaign_manager/data_migration_mongo.py
import os
import django # To use Django settings for MONGO_URI etc.
import psycopg2
import psycopg2.extras
from pymongo import MongoClient, UpdateOne, ReplaceOne
from bson import ObjectId # Not strictly needed for insertion if Pymongo handles string IDs, but good for clarity
import uuid as py_uuid # For generating new UUIDs if source is missing
from datetime import datetime

# Set up Django environment to access settings
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'listmonk_clone.listmonk_clone.settings')
django.setup()
from django.conf import settings

# --- Configuration for Listmonk Source PostgreSQL Database ---
LISTMONK_PG_CONFIG = {
    'dbname': os.environ.get('LISTMONK_PG_DBNAME', 'listmonk_source_db_name'), # Example: Use env vars
    'user': os.environ.get('LISTMONK_PG_USER', 'listmonk_source_user'),
    'password': os.environ.get('LISTMONK_PG_PASSWORD', 'listmonk_source_password'),
    'host': os.environ.get('LISTMONK_PG_HOST', 'localhost'),
    'port': os.environ.get('LISTMONK_PG_PORT', '5432'),
}

# --- MongoDB Connection ---
MONGO_URI = settings.MONGO_URI
MONGO_DB_NAME = settings.MONGO_DB_NAME
mongo_client = None
mongo_db = None

def get_mongo_db_connection():
    global mongo_client, mongo_db
    if mongo_db is None:
        try:
            mongo_client = MongoClient(MONGO_URI)
            mongo_client.admin.command('ping') # Verify connection
            mongo_db = mongo_client[MONGO_DB_NAME]
            print("Successfully connected to MongoDB for migration.")
        except Exception as e:
            print(f"Error connecting to MongoDB for migration: {e}")
            raise
    return mongo_db


def get_pg_connection():
    return psycopg2.connect(**LISTMONK_PG_CONFIG)

# --- Migration Functions ---

def migrate_subscribers(pg_conn, mongo_db_conn):
    print("Starting subscriber migration to MongoDB...")
    pg_cursor = pg_conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
    subscribers_collection = mongo_db_conn["subscribers"]

    # Create indexes if they don't exist (idempotent)
    subscribers_collection.create_index("uuid", unique=True)
    subscribers_collection.create_index("email", unique=True)
    subscribers_collection.create_index("status")

    pg_cursor.execute("SELECT id, uuid, email, name, attribs, status, created_at, updated_at FROM subscribers")

    operations = []
    migrated_count = 0
    skipped_count = 0

    for row in pg_cursor:
        try:
            doc = {
                "uuid": str(row["uuid"]),
                "email": row["email"].lower(),
                "name": row["name"],
                "attribs": row["attribs"] if row["attribs"] else {},
                "status": row["status"], # Assuming status strings match conceptual schema
                "created_at": row["created_at"],
                "updated_at": row["updated_at"]
                # _id will be auto-generated by MongoDB
            }
            # Using ReplaceOne with upsert=True to make it idempotent based on UUID
            operations.append(ReplaceOne({"uuid": doc["uuid"]}, doc, upsert=True))
            migrated_count +=1 # Counts potential inserts/updates

            if len(operations) >= 500: # Batch operations
                subscribers_collection.bulk_write(operations)
                print(f"Processed batch of {len(operations)} subscribers.")
                operations = []
        except Exception as e:
            print(f"Error preparing subscriber {row['email']}: {e}")
            skipped_count += 1

    if operations:
        subscribers_collection.bulk_write(operations)
        print(f"Processed final batch of {len(operations)} subscribers.")

    pg_cursor.close()
    print(f"Subscriber migration: {migrated_count} prepared for upsert, {skipped_count} skipped due to errors.")


def migrate_mailing_lists(pg_conn, mongo_db_conn):
    print("Starting mailing list migration to MongoDB...")
    pg_cursor = pg_conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
    lists_collection = mongo_db_conn["mailing_lists"]

    lists_collection.create_index("uuid", unique=True)
    lists_collection.create_index("name")
    lists_collection.create_index("type")

    pg_cursor.execute("SELECT id, uuid, name, description, type, optin, tags, created_at, updated_at FROM lists")

    operations = []
    migrated_count = 0
    for row in pg_cursor:
        doc = {
            "uuid": str(row["uuid"]),
            "name": row["name"],
            "description": row["description"] or "",
            "type": row["type"], # e.g., "public", "private"
            "optin_type": row["optin"], # e.g., "single", "double"
            "tags": row["tags"] if row["tags"] else [],
            "subscriber_count": 0, # Initialize; will be updated by a separate process or task
            "created_at": row["created_at"],
            "updated_at": row["updated_at"]
        }
        operations.append(ReplaceOne({"uuid": doc["uuid"]}, doc, upsert=True))
        migrated_count += 1
        if len(operations) >= 500:
            lists_collection.bulk_write(operations)
            print(f"Processed batch of {len(operations)} mailing lists.")
            operations = []

    if operations:
        lists_collection.bulk_write(operations)
        print(f"Processed final batch of {len(operations)} mailing lists.")

    pg_cursor.close()
    print(f"Mailing list migration: {migrated_count} prepared for upsert.")


def migrate_subscriptions(pg_conn, mongo_db_conn):
    print("Starting subscriptions migration to MongoDB...")
    pg_cursor = pg_conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
    subscriptions_collection = mongo_db_conn["subscriptions"]

    # For mapping PG int IDs to Mongo ObjectIds (or UUIDs if preferred for linking)
    # We'll use UUIDs from the already migrated subscribers and lists collections.
    subscribers_map = {s["uuid"]: s["_id"] for s in mongo_db_conn["subscribers"].find({}, {"uuid": 1, "_id": 1})}
    lists_map = {l["uuid"]: l["_id"] for l in mongo_db_conn["mailing_lists"].find({}, {"uuid": 1, "_id": 1})}

    subscriptions_collection.create_index([("subscriber_id", 1), ("list_id", 1)], unique=True)
    subscriptions_collection.create_index([("list_id", 1), ("status", 1)])

    # Fetch original subscriber and list UUIDs from source for mapping
    pg_cursor.execute("""
        SELECT sl.subscriber_id as lm_subscriber_id,
               sl.list_id as lm_list_id,
               s.uuid as subscriber_uuid,
               l.uuid as list_uuid,
               sl.meta, sl.status, sl.created_at, sl.updated_at
        FROM subscriber_lists sl
        JOIN subscribers s ON sl.subscriber_id = s.id
        JOIN lists l ON sl.list_id = l.id
    """)

    operations = []
    migrated_count = 0
    skipped_count = 0
    for row in pg_cursor:
        try:
            subscriber_pg_uuid = str(row["subscriber_uuid"])
            list_pg_uuid = str(row["list_uuid"])

            subscriber_mongo_id = subscribers_map.get(subscriber_pg_uuid)
            list_mongo_id = lists_map.get(list_pg_uuid)

            if not subscriber_mongo_id or not list_mongo_id:
                print(f"Skipping subscription: Subscriber UUID {subscriber_pg_uuid} or List UUID {list_pg_uuid} not found in migrated MongoDB data.")
                skipped_count += 1
                continue

            doc = {
                "subscriber_id": subscriber_mongo_id, # Store ObjectId ref
                "list_id": list_mongo_id,           # Store ObjectId ref
                "status": row["status"],
                "meta": row["meta"] if row["meta"] else {},
                "subscribed_at": row["created_at"], # Assuming created_at of subscription is subscribed_at
                "created_at": row["created_at"],
                "updated_at": row["updated_at"]
            }
            # Using subscriber_id and list_id as the unique key for upsert
            operations.append(ReplaceOne({"subscriber_id": doc["subscriber_id"], "list_id": doc["list_id"]}, doc, upsert=True))
            migrated_count +=1

            if len(operations) >= 1000:
                subscriptions_collection.bulk_write(operations)
                print(f"Processed batch of {len(operations)} subscriptions.")
                operations = []
        except Exception as e:
            print(f"Error migrating subscription for Listmonk sub_id {row['lm_subscriber_id']}, list_id {row['lm_list_id']}: {e}")
            skipped_count += 1

    if operations:
        subscriptions_collection.bulk_write(operations)
        print(f"Processed final batch of {len(operations)} subscriptions.")

    pg_cursor.close()
    print(f"Subscription migration: {migrated_count} prepared for upsert, {skipped_count} skipped.")


def migrate_templates(pg_conn, mongo_db_conn):
    print("Starting template migration to MongoDB...")
    # Similar to subscribers/lists, map fields.
    # Ensure 'is_default' logic is handled (e.g., only one default per type).
    # This might require querying Mongo first if multiple defaults exist in PG for a type.
    print("Template migration SKIPPED (placeholder).")

def migrate_campaigns(pg_conn, mongo_db_conn):
    print("Starting campaign migration to MongoDB...")
    # Complex:
    # - Map PG template_id to Mongo template ObjectId (via UUID map).
    # - Map PG list_ids (from campaign_lists) to Mongo list ObjectIds (via UUID map) and store in `target_list_ids`.
    # - Initialize `stats` subdocument.
    # - Map `archive_template_id`.
    print("Campaign migration SKIPPED (placeholder).")


def main_migration():
    print("Starting PostgreSQL to MongoDB data migration...")
    pg_conn = None
    # mongo_client already defined globally, get_mongo_db_connection will init if needed

    try:
        pg_conn = get_pg_connection()
        mongo_db_conn = get_mongo_db_connection() # Initializes global mongo_db
        print("Successfully connected to source PostgreSQL and target MongoDB.")

        # Order of migration is important
        migrate_subscribers(pg_conn, mongo_db_conn)
        migrate_mailing_lists(pg_conn, mongo_db_conn)
        migrate_subscriptions(pg_conn, mongo_db_conn) # Depends on subscribers and lists

        migrate_templates(pg_conn, mongo_db_conn)
        migrate_campaigns(pg_conn, mongo_db_conn) # Depends on templates, lists

        # TODO: Migrate other entities: links, tracking_events (from campaign_views, link_clicks), bounces, media_assets

        print("Data migration process completed (or reached end of implemented steps).")

    except psycopg2.Error as e:
        print(f"PostgreSQL connection error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred during migration: {e}")
    finally:
        if pg_conn:
            pg_conn.close()
            print("PostgreSQL source database connection closed.")
        if mongo_client: # Use the global client instance to close
            mongo_client.close()
            print("MongoDB target database connection closed.")

if __name__ == '__main__':
    print("Data migration script (PostgreSQL to MongoDB) invoked.")
    print("IMPORTANT: Ensure environment variables for PG connection and Django settings for MongoDB are correct.")
    print("Backup both databases before running.")
    # main_migration() # Uncomment to run after careful review and setup.
    print("Migration run commented out by default. Review and uncomment main_migration() to execute.")
